
model_type: HiVAE
activation_fct: RELU
n_latent_hierarchy_lvls: 4
n_encoder_layer_nodes: 500
n_encoder_layers: 2
encoder_hidden_nodes: 
  - 512
  - 256
decoder_hidden_nodes: 
  - 256
  - 512
n_latent_nodes: 16
